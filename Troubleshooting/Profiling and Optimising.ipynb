{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling and Optimising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gprof** - for C\n",
    "\n",
    "**cProfile** - for Python count function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the right data structures\n",
    "\n",
    "#### lists (python) - arraylist (java) - vector (c++) - array (ruby) - slice (go) - quick to add/remove last element\n",
    "- adding elements in the beginning is slow\n",
    "- going through the whole lists\n",
    "\n",
    "#### dictionary (python) - HashMap (Java) - Unordered Map (C++) - Hash (Ruby) - Map (Go)\n",
    "- looking up keys in one operation yep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- use cache ot store intermediate result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling in ubuntu command line (for python scripts):\n",
    "    \n",
    "- `!time` - just to get 3 time values\n",
    "    - real: actual time to execute the command ( sometimes called wall-clock time) no matter what computer is doing \n",
    "    - user: time spent doing operations in the user space\n",
    "    - sys: time spent doing system value operations\n",
    "   \n",
    "   \n",
    "- `!pprofile3`\n",
    "    !`pprofile3 -f callgrind -o profile.out ./send_reminders.py`\n",
    "    \n",
    "    #### plots the call and time graph in prifle visualizer\n",
    "    \n",
    "    !`kcachegrind` profile.out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concurrency**  - is the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome\n",
    "\n",
    "- no shared data = `CPU - network IO - disk IO` ~ can run in parallel without interfering with each other\n",
    "\n",
    "- shared data = threads (not handled by OS)\n",
    "\n",
    "    - in `python` we can use **Threading**, **AsynchIO**\n",
    "\n",
    "    - I/O bound - waiting for input or output\n",
    "    - CPU bound - running operations in parallel using all available CPU time\n",
    "    - `Trade off`: simoltaneous actions vs starving system for resources (like splitting into too many processes one big task and switching in between of the tasks would take more time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the growth of data \n",
    "\n",
    "#### csv -> SQLite file -> database server (maybeon diff machine) -> dynamic casher in front of database server to run it even faster\n",
    "\n",
    "- `SQLite` - lightweight database system that lets query the information stored in file without needing to run a database server\n",
    "- cashing service - `Varnish`\n",
    "- if not enough - distribute the service across diff computers (use virtual machines in cloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slowness -> bottleneck -> good monitoring infrostructure for complex systems\n",
    "\n",
    "- if web server is waiting on network calls, but **database spends time on Disk I/O** -> problem how data is accessed in database -> look at indexes in the database vs too many indexes (adding or modifying entries can become slow because lots of indexes would need updated) so fields that are actually used -> if still not solved and database server has too many quesries: cache or disribute data (to separate database servers)\n",
    "\n",
    "- if **CPU saturated** -> improve code of the service -> use cash -> if still not enough - distribute the load to more computers to system -> distributed system -> dummy check: optimize system itself & re-chekc whether we still need that part of system\n",
    "    - disk latency  - time that it takes to complete a single I/O operation on a block device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study:\n",
    "- process full size images to thumbnails (small images)\n",
    "- try simple solution on smaller batch and use `time command`\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
